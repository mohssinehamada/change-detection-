# -*- coding: utf-8 -*-
"""CDutils.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1wkcPZddI945P9znwOzEYQUFzdrfxUGWp
"""

# Commented out IPython magic to ensure Python compatibility.
import sys
import os
import numpy as np
import PIL
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

import torch
import torchvision
import torchvision.transforms as T

# Transform Image
def open_image(fname, size=256):
    img = np.array(PIL.Image.open(fname).resize((size, size)))
    t = torch.Tensor(img)
    return t.permute(2,0,1).float()/255.0

# Transform Mask
def open_mask(fname, size=256):
    img = np.array(PIL.Image.open(fname).resize((size, size)))
    t = torch.Tensor(img).float()/255.0
    #t3d = torch.stack((t,t,t)) # convert to 3d
    return t

def visualize_image(processed):
  tensorToimg = T.ToPILImage()
  # Plot
  fig = plt.figure(figsize=(30, 50))
  for i in range(len(processed)):
    a = fig.add_subplot(5, 4, i+1)
    imgplot = plt.imshow(tensorToimg(processed[i].squeeze(0)))
    a.axis("off")
    #plt.savefig(path_train_example_damage + '_1' + str('feature_maps.jpg'), bbox_inches='tight')
  return

def get_features(image, conv_layers):
  outputs = []
  names = []
  for layer in conv_layers[0:]:
    image = layer(image)
    outputs.append(image)
    names.append(layer)
  return names, outputs

def process_features(outputs):
  processed = []
  for feature_map in outputs:
     feature_map = feature_map.squeeze(0)
     gray_scale = torch.sum(feature_map,0)
     gray_scale = gray_scale / feature_map.shape[0]
     processed.append(gray_scale.data.cpu().numpy())
  return processed

def plot_featuremap(processed):
  fig = plt.figure(figsize=(30, 50))
  for i in range(len(processed)):
    a = fig.add_subplot(5, 4, i+1)
    imgplot = plt.imshow(processed[i])
    a.axis("off")
  return
